https://docs.confluent.io/current/quickstart/cos-docker-quickstart.html#cos-docker-quickstart

https://docs.confluent.io/current/ksql/docs/tutorials/basics-docker.html

Create Kafka Topics :

users :
docker-compose exec broker kafka-topics --create --zookeeper \
zookeeper:2181 --replication-factor 1 --partitions 1 --topic users

print 'users';

pageviews :
docker-compose exec broker kafka-topics --create --zookeeper \
zookeeper:2181 --replication-factor 1 --partitions 1 --topic pageviews

print 'pageviews';

Install a Kafka Connector and Generate Sample Data :

docker-compose exec ksql-server ksql-datagen

pageviews :
wget https://github.com/confluentinc/kafka-connect-datagen/raw/master/config/connector_pageviews_cos.config
curl -X POST -H "Content-Type: application/json" --data @connector_pageviews_cos.config http://localhost:8083/connectors

users :
wget https://github.com/confluentinc/kafka-connect-datagen/raw/master/config/connector_users_cos.config
curl -X POST -H "Content-Type: application/json" --data @connector_users_cos.config http://localhost:8083/connectors

Create and Write to a Stream and Table using KSQL :
Create Streams and Tables

Create a stream pageviews from the Kafka topic pageviews, specifying the value_format of AVRO.
CREATE STREAM pageviews (viewtime BIGINT, userid VARCHAR, pageid VARCHAR) \
WITH (KAFKA_TOPIC='pageviews', VALUE_FORMAT='AVRO');

Create a table users with several columns from the Kafka topic users, with the value_format of AVRO.
CREATE TABLE users (registertime BIGINT, gender VARCHAR, regionid VARCHAR,  \
userid VARCHAR) \
WITH (KAFKA_TOPIC='users', VALUE_FORMAT='AVRO', KEY = 'userid');

Write Queries
SET 'auto.offset.reset'='earliest';

Create a non-persistent query that returns data from a stream with the results limited to a maximum of three rows.
SELECT pageid FROM pageviews LIMIT 3;

CREATE STREAM pageviews_female
AS SELECT users.userid AS userid, pageid, regionid, gender FROM pageviews
LEFT JOIN users ON pageviews.userid = users.userid
WHERE gender = 'FEMALE';

CREATE STREAM pageviews_female_like_89
WITH (kafka_topic='pageviews_enriched_r8_r9', value_format='AVRO')
AS SELECT *
FROM pageviews_female
WHERE regionid LIKE '%_8' OR regionid LIKE '%_9';

CREATE TABLE pageviews_regions AS SELECT gender, regionid , COUNT(*) AS numusers
FROM pageviews_female WINDOW TUMBLING (size 30 second)
GROUP BY gender, regionid HAVING COUNT(*) > 1;

Monitor Streaming Data :

DESCRIBE EXTENDED pageviews_female_like_89;

EXPLAIN CTAS_PAGEVIEWS_REGIONS_2;

SELECT * FROM pageviews_regions LIMIT 5;
SELECT pageid FROM pageviews_original LIMIT 3;
SELECT * FROM pageviews_enriched;
SELECT * FROM pageviews_regions LIMIT 5;

